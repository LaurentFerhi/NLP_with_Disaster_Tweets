{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real or Not? NLP with Disaster Tweets\n",
    "Predict which Tweets are about real disasters and which ones are not\n",
    "\n",
    "https://www.kaggle.com/c/nlp-getting-started/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pickle as pk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['keyword','location'], axis=1, inplace=True)\n",
    "test.drop(['keyword','location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check size of each category\n",
    "train.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laure\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load english stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing text + cleaning + stemm\n",
    "def parse_out_text(all_text):\n",
    "    # clean punctuation, make lower case and remove stopwords\n",
    "    text_string = all_text.translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \")\n",
    "    text_string = [word.lower() for word in text_string if word.lower() not in stopwords.words('english')]\n",
    "    # Stemm text\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for  word in text_string]\n",
    "    words = \" \".join(stemmed) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Had an awesome time visiting the CFC head office the ancop site and ablaze. Thanks to Tita Vida for taking care of us ??'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text example\n",
    "text_test = train['text'].iloc[42]\n",
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awesom time visit cfc head offic ancop site ablaz thank tita vida take care us '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsed text example\n",
    "parse_out_text(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsed_train = pd.DataFrame(train['text'].apply(parse_out_text))\n",
    "parsed_train['target'] = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsed_test = pd.DataFrame(test['text'].apply(parse_out_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(parsed_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the words in all the texts and increment the counts in the appropriate counter objects\n",
    "def count_most_common(cat,number):\n",
    "    count_word = Counter()\n",
    "    df_cat = parsed_train[parsed_train['target'] == cat]\n",
    "    for article in df_cat['text']:\n",
    "        for word in article.split(\" \"):\n",
    "            count_word[word] += 1\n",
    "    return count_word.most_common(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1166),\n",
       " ('fire', 264),\n",
       " ('bomb', 178),\n",
       " ('kill', 158),\n",
       " ('news', 132),\n",
       " ('via', 121),\n",
       " ('flood', 120),\n",
       " ('disast', 116),\n",
       " ('california', 115),\n",
       " ('crash', 110)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_most_common(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1569),\n",
       " ('like', 306),\n",
       " ('im', 241),\n",
       " ('get', 220),\n",
       " ('amp', 192),\n",
       " ('new', 168),\n",
       " ('go', 142),\n",
       " ('dont', 139),\n",
       " ('one', 134),\n",
       " ('bodi', 116)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_most_common(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 peopl receiv wildfir evacu order califor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>two giant crane hold bridg collaps nearbi home...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>ariaahrari thetawniest control wild fire calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>m194 0104 utc5km volcano hawaii httptcozdtoyd8ebj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>latest home raze northern california wildfir  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0             deed reason earthquak may allah forgiv us       1\n",
       "1                  forest fire near la rong sask canada       1\n",
       "2     resid ask shelter place notifi offic evacu she...       1\n",
       "3     13000 peopl receiv wildfir evacu order califor...       1\n",
       "4     got sent photo rubi alaska smoke wildfir pour ...       1\n",
       "...                                                 ...     ...\n",
       "7608  two giant crane hold bridg collaps nearbi home...       1\n",
       "7609  ariaahrari thetawniest control wild fire calif...       1\n",
       "7610  m194 0104 utc5km volcano hawaii httptcozdtoyd8ebj       1\n",
       "7611  polic investig ebik collid car littl portug eb...       1\n",
       "7612  latest home raze northern california wildfir  ...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_train_text = np.array(parsed_train['text'])\n",
    "parsed_test_text = np.array(parsed_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disco',\n",
       " 'discov',\n",
       " 'discoveri',\n",
       " 'discuss',\n",
       " 'disea',\n",
       " 'diseas',\n",
       " 'disgust',\n",
       " 'dismiss',\n",
       " 'disney',\n",
       " 'disord']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Implement vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Fit transform train data\n",
    "X_train_vector = vectorizer.fit_transform(parsed_train_text)\n",
    "X_train_vector = X_train_vector.toarray()\n",
    "\n",
    "# display some words from the vectorizer\n",
    "words = vectorizer.get_feature_names()\n",
    "words[1500:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply vectorizer to test data\n",
    "X_test_vector = vectorizer.transform(parsed_test_text)\n",
    "X_test_vector = X_test_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract targets from train data\n",
    "y_train_target = np.array(parsed_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vector shape: (7613, 10000)\n",
      "y_train_target shape: (7613,)\n",
      "X_test_vector shape: (3263, 10000)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_vector shape:',X_train_vector.shape)\n",
    "print('y_train_target shape:',y_train_target.shape)\n",
    "print('X_test_vector shape:',X_test_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_vector, \n",
    "    y_train_target, \n",
    "    stratify=y_train_target, \n",
    "    test_size=0.15, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6471, 10000)\n",
      "y_train shape: (6471,)\n",
      "X_test shape: (1142, 10000)\n",
      "y_test shape: (1142,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validator : ShuffleSplit \n",
    "sss = StratifiedShuffleSplit(n_splits = 20, test_size = 0.2, random_state = 42) # To avoid over-fitting\n",
    "\n",
    "### Import classifier ###\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "\n",
    "# definition of the pipeline\n",
    "pipeline = Pipeline(steps = [\n",
    "    (\"LSVC\",clf)\n",
    "])\n",
    "\n",
    "# parameters to tune \n",
    "param_grid = {\n",
    "    'LSVC__C' : [1],\n",
    "    'LSVC__class_weight' : ['balanced'],\n",
    "    'LSVC__multi_class' : ['ovr'],\n",
    "    'LSVC__random_state' : [42],\n",
    "    'LSVC__max_iter' : [10000],\n",
    "}  \n",
    "\n",
    "# exhaustive search over specified parameter\n",
    "grid = GridSearchCV(pipeline, param_grid, verbose = 1, cv = sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > training classifier:\n",
      "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " > Best grid search:\n",
      "{'LSVC__C': 1, 'LSVC__class_weight': 'balanced', 'LSVC__max_iter': 10000, 'LSVC__multi_class': 'ovr', 'LSVC__random_state': 42}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       651\n",
      "           1       0.78      0.75      0.76       491\n",
      "\n",
      "    accuracy                           0.80      1142\n",
      "   macro avg       0.80      0.80      0.80      1142\n",
      "weighted avg       0.80      0.80      0.80      1142\n",
      "\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training classifier\n",
    "print (\" > training classifier:\")\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "# best classifier using the cross-validator and the Stratified Shuffle Split \n",
    "clf = grid.best_estimator_\n",
    "\n",
    "# print grid parameters\n",
    "print (\"\\n > Best grid search:\")\n",
    "print (grid.best_params_)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(clf, X_train, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.matshow(conf_mx, cmap='Blues')\n",
    "\n",
    "for (x, y), value in np.ndenumerate(conf_mx):\n",
    "    plt.text(x, y, f\"{value:.0f}\", va=\"center\", ha=\"center\", \n",
    "             bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump classifier in a pickle file\n",
    "with open(\"disaster.pkl\", 'wb') as file:\n",
    "    pk.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load categories\n",
    "with open(\"disaster.pkl\", 'rb') as fid:\n",
    "    trained_clf = pk.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_clf.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1924\n",
       "1    1339\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'id':np.array(test['id']),\n",
    "    'text':np.array(test['text']),\n",
    "    'target':trained_clf.predict(X_test_vector)\n",
    "})\n",
    "\n",
    "df_results['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>6460</td>\n",
       "      <td>I made him fall and hegot injured https://t.co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>8619</td>\n",
       "      <td>#Sismo DETECTADO #JapÌ_n [Report 6] 01:02:42 O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>4134</td>\n",
       "      <td>#KondoByJaymOnI U.S. in record hurricane droug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>3441</td>\n",
       "      <td>HillaryÛªs Bimbo Eruptions and Questionable F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>4346</td>\n",
       "      <td>A dust storm in Pheonix. http://t.co/AMgfOnzUSD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  target\n",
       "1916  6460  I made him fall and hegot injured https://t.co...       1\n",
       "2589  8619  #Sismo DETECTADO #JapÌ_n [Report 6] 01:02:42 O...       1\n",
       "1257  4134  #KondoByJaymOnI U.S. in record hurricane droug...       1\n",
       "1047  3441  HillaryÛªs Bimbo Eruptions and Questionable F...       1\n",
       "1319  4346    A dust storm in Pheonix. http://t.co/AMgfOnzUSD       1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['target'] == 1].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>8323</td>\n",
       "      <td>@KurtSchlichter Grandpa fought his way across ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>2653</td>\n",
       "      <td>pkadlik : jojowizphilipp and I have a crush on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1678</td>\n",
       "      <td>Project Syndicate: A Marshall Plan for the Uni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>5820</td>\n",
       "      <td>Created save #666 on my current Fallout 3 play...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>7347</td>\n",
       "      <td>Watch Sarah Palin OBLITERATE Planned Parenthoo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  target\n",
       "2494  8323  @KurtSchlichter Grandpa fought his way across ...       0\n",
       "808   2653  pkadlik : jojowizphilipp and I have a crush on...       0\n",
       "512   1678  Project Syndicate: A Marshall Plan for the Uni...       0\n",
       "1725  5820  Created save #666 on my current Fallout 3 play...       0\n",
       "2195  7347  Watch Sarah Palin OBLITERATE Planned Parenthoo...       0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['target'] == 0].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = df_results.drop('text',axis=1)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
